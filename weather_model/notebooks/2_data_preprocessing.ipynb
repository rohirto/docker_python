{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1662/3049972813.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Evaluation function\n",
    "def data_evaluation(data):\n",
    "    \"\"\"Function to See the Data Evaluation, sees shape, head and describe\n",
    "\n",
    "    Args:\n",
    "        data (dataframe): Pandas Dataframe\n",
    "    \"\"\"\n",
    "    print(f\"{data.Name} Shape: {data.shape}\")\n",
    "    print(f\"{data.Name} Head:\\n{data.head()} \")\n",
    "    print(f\"{data.Name} Summary Statistics:\\n{data.describe()}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"{data.Name} Columns:\\n{data.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PickleShareDB' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-r humidity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-r temperature\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m humidity\u001b[38;5;241m.\u001b[39mName \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhumidity\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2456\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2454\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2456\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2458\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2459\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2460\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/IPython/extensions/storemagic.py:148\u001b[0m, in \u001b[0;36mStoreMagics.store\u001b[0;34m(self, parameter_s)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args:\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 148\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mdb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mautorestore/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'PickleShareDB' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "%store -r humidity\n",
    "%store -r temperature\n",
    "humidity.Name = 'humidity'\n",
    "temperature.Name = 'temperature'\n",
    "# Data Processing starts from here\n",
    "if 'context_humidity' in humidity.columns:\n",
    "    # Drop context Frame\n",
    "    humidity.drop('context_humidity', axis=1, inplace=True)\n",
    "if 'context_temperature' in temperature.columns:\n",
    "    temperature.drop('context_temperature', axis = 1, inplace=True)\n",
    "\n",
    "# See the data after droping the context coloumn\n",
    "print(\"After Dropping Context: \")\n",
    "data_evaluation(humidity)\n",
    "data_evaluation(temperature)\n",
    "\n",
    "# Remove Zero from the dataset\n",
    "humidity = humidity[humidity['humidity'] != 0]\n",
    "temperature = temperature[temperature['temperature'] != 0]\n",
    "\n",
    "humidity.Name = 'humidity'\n",
    "temperature.Name = 'temperature'\n",
    "# See the data after removing zeroes\n",
    "print(\"Removing Zeroes: \")\n",
    "data_evaluation(humidity)\n",
    "data_evaluation(temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'humidity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Normalization of data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Convert Unix timestamps to datetime objects\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m humidity[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mhumidity\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m], unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m temperature[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(temperature[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m], unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Sort both DataFrames by the 'Datetime' column\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'humidity' is not defined"
     ]
    }
   ],
   "source": [
    "#Normalization of data\n",
    "# Convert Unix timestamps to datetime objects\n",
    "humidity['Datetime'] = pd.to_datetime(humidity['timestamp'], unit='ms')\n",
    "temperature['Datetime'] = pd.to_datetime(temperature['timestamp'], unit='ms')\n",
    "\n",
    "# Sort both DataFrames by the 'Datetime' column\n",
    "humidity.sort_values(by='Datetime', inplace=True)\n",
    "temperature.sort_values(by='Datetime', inplace=True)\n",
    "\n",
    "# Set the tolerance in seconds\n",
    "tolerance = pd.Timedelta(seconds=10)\n",
    "\n",
    "# Merge dataframes based on the common timestamps within the tolerance\n",
    "merged_df = pd.merge_asof(humidity, temperature,\n",
    "                          on='Datetime', direction='nearest', tolerance=tolerance)\n",
    "\n",
    "# Drop the 'Datetime' column as it's no longer needed\n",
    "merged_df.drop(columns=['Datetime'], inplace=True)\n",
    "merged_df.Name = 'merged frame'\n",
    "data_evaluation(merged_df)\n",
    "\n",
    "X = merged_df[['humidity', 'temperature']]\n",
    "\n",
    "X = X.dropna()\n",
    "\n",
    "# Data Visualization before Scaling\n",
    "scatter_matrix(merged_df.iloc[:,[1,4]])\n",
    "plt.savefig(\"../output/n_plot_merged.png\")\n",
    "plt.show()\n",
    "\n",
    "# Do the Scaling\n",
    "# instantiate the scaler\n",
    "scale = StandardScaler()\n",
    "# compute the mean and std to be used later for scaling\n",
    "scale.fit(X)\n",
    "# This are raw values\n",
    "print(\"Mean and std before scale \")\n",
    "print(scale.mean_)\n",
    "print(scale.scale_)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Now we Transform/Scale the data around 0,0\n",
    "X_scaled = scale.transform(X)\n",
    "# Let’s do a sanity check to see if each feature is centered at 0 and has a std of 1:\n",
    "print(X_scaled.mean(axis=0))  # Mean comes down almost to zero, as data is scaled around 0,0\n",
    "print(X_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'X_scaled' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store X_scaled"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
