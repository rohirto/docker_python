{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # Plotiing\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-21T16:33:19.912918Z","iopub.execute_input":"2023-09-21T16:33:19.913345Z","iopub.status.idle":"2023-09-21T16:33:20.277051Z","shell.execute_reply.started":"2023-09-21T16:33:19.913303Z","shell.execute_reply":"2023-09-21T16:33:20.276228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Iris Flower Data set \nIris is a flower wih following features\n![](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Machine+Learning+R/iris-machinelearning.png)","metadata":{}},{"cell_type":"code","source":"\"\"\" Step 1 Data exploration \"\"\"\n# Check if running on Kaggle Notebook (you can define your own check)\nif 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n    # Load dataset from Kaggle\n    iris = pd.read_csv('/kaggle/input/sololearn-iris/iris.csv')\nelse:\n    # Load dataset locally\n    iris = pd.read_csv('/workspaces/docker_python/data_science/datasets/iris.csv')\n   \n\n# Print the shape of dataset\nprint(iris.shape)\n\n# Print the head\nprint(iris.head())\n\n# Check the summary statistics\nprint(iris.describe())\n\n# 'id' column is of no use thus we drop it\niris.drop('id', axis=1, inplace=True)\n\nprint(iris.head())\n\n# To view the classes of categorical variable, 2 Methods\nprint(iris.groupby('species').size())\n\nprint(iris['species'].value_counts())\n# The above dataset is a balanced dataset, its opposite being unbalanced dataset\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T16:33:20.279014Z","iopub.execute_input":"2023-09-21T16:33:20.279881Z","iopub.status.idle":"2023-09-21T16:33:20.351683Z","shell.execute_reply.started":"2023-09-21T16:33:20.279838Z","shell.execute_reply":"2023-09-21T16:33:20.350171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\" Data Visualization \"\"\"\n\n# Univariate Plots of Features\niris.hist()\nplt.show()\n\n# Multivariate Plotiing\n# build a dict mapping species to an integer code\ninv_name_dict = {'iris-setosa': 0,\n'iris-versicolor': 1,\n'iris-virginica': 2}\n\n# build integer color code 0/1/2\ncolors = [inv_name_dict[item] for item in iris['species']] # assigns the color code 0/1/2 to the cloumn 'species'\nprint(colors)\n# scatter plot of sepals\nscatter = plt.scatter(iris['sepal_len'], iris['sepal_wd'], c = colors)\nplt.xlabel('sepal length (cm)')\nplt.ylabel('sepal width (cm)')\n## add legend\nplt.legend(handles=scatter.legend_elements()[0],\nlabels = inv_name_dict.keys())\nplt.savefig(\"plot.png\")\nplt.show()\n\n# scatter plot of petals\n# scatter plot\nscatter = plt.scatter(iris['petal_len'], iris['petal_wd'],c = colors)\nplt.xlabel('petal length (cm)')\nplt.ylabel('petal width (cm)')\n# add legend\nplt.legend(handles= scatter.legend_elements()[0],\n  labels = inv_name_dict.keys())\nplt.show()\n\n# Scatter matrix\npd.plotting.scatter_matrix(iris)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T16:33:20.353788Z","iopub.execute_input":"2023-09-21T16:33:20.354260Z","iopub.status.idle":"2023-09-21T16:33:22.576606Z","shell.execute_reply.started":"2023-09-21T16:33:20.354207Z","shell.execute_reply":"2023-09-21T16:33:22.575491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"K nearest neighbors\nK nearest neighbors (knn) is a supervised machine learning model that takes a data point, looks at its 'k' closest labeled data points, and assigns the label by a majority vote.\n\nHere we see that changing k could affect the output of the model. In knn, k is a hyperparameter. A hyperparameter in machine learning is a parameter whose value is set before the learning process begins.\n\nFor example, in the figure below, there are two classes: blue squares and red triangles. What label should we assign to the green dot, with unknown label, based on the 3nn algorithm, i.e., when k is 3? Of the 3 closest data points from the green dot (solid line circle), two are red triangles and one is blue square, thus the green dot is predicted to be a red triangle. If k is 5 (dashed line circle), it is then classified as a blue square (3 blue squares versus 2 red triangles, blue squares are the majority).\n\n![](https://lecontent.sololearn.com/material-images/00000d0d00000445531d0000fe0e0000_data%20visualization.png)","metadata":{}},{"cell_type":"code","source":"\"\"\" Modelling \"\"\"\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Set the features and Target\nX = iris[['petal_len', 'petal_wd']]\ny = iris['species']\n\n# Split the test data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1,stratify=y)\n\n# Print the categorical count of train and test data \nprint(y_train.value_counts())\nprint(y_test.value_counts())\n\n## instantiate \nknn = KNeighborsClassifier(n_neighbors=5)\n\n## fit \nprint(knn.fit(X_train, y_train))\nprint(\"\\n\")\n\n## Predict on test dataset\ny_pred = knn.predict(X_test)\nprint(y_pred[:5])\nprint(\"\\n\")\nprint(y_pred[10:12]) # See the prediction on 11th and 12th elements\n\n## Probablity Prediction - Doesnot label class output but probability of being classified to that class\ny_pred_prob = knn.predict_proba(X_test)\nprint(y_pred_prob[10:12]) # predict for 11, 12 -> for 10th ele [1. 0. 0.] \n                          # Which means probability of the 11th flower being\n                          # predicted an iris-setosa is 1, an iris-versicolor\n                          # and an iris-virginica are both 0.\n                          # For the next flower, there is a 20% chance that it\n                          # would be classified as iris-versicolor but 80% chance to be iris-virginica.\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T16:33:22.578354Z","iopub.execute_input":"2023-09-21T16:33:22.578837Z","iopub.status.idle":"2023-09-21T16:33:22.841516Z","shell.execute_reply.started":"2023-09-21T16:33:22.578808Z","shell.execute_reply":"2023-09-21T16:33:22.840075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For Above Cell, explanation: \nProbability Prediction: For example, the probability of the 11th flower being predicted an iris-setosa is 1, an iris-versicolor and an iris-virginica are both 0. For the next flower, there is a 20% chance that it would be classified as iris-versicolor but 80% chance to be iris-virginica. What it tells us is that of the five nearest neighbours of the 12th flower in the testing set, 1 is an iris-versicolor, the rest 4 are iris-virginica.","metadata":{}},{"cell_type":"code","source":"\"\"\" Model Evaluation \"\"\"\n# To measure Accuracy\n\n# Check how many correct predictions were made\nprint((y_pred==y_test.values).sum()) # Correct Predictions\nprint(y_test.size) # Total Test size\n\n# Effiecency \nprint((y_pred==y_test.values).sum()/y_test.size)\nprint(\"\\n\")\n# Effiecency r_score\nprint(knn.score(X_test, y_test))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T16:33:22.843122Z","iopub.execute_input":"2023-09-21T16:33:22.843519Z","iopub.status.idle":"2023-09-21T16:33:22.859346Z","shell.execute_reply.started":"2023-09-21T16:33:22.843484Z","shell.execute_reply":"2023-09-21T16:33:22.857206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above code shows our model made 1 mistake\n\nClassification accuracy alone can be misleading if there is an unequal number of observations in each class or if there are more than two classes in the dataset.\n\nCalculating a confusion matrix will provide a better idea of what the classification is getting right and what types of errors it is making.\n\nWhat is a confusion matrix? It is a summary of the counts of correct and incorrect predictions, broken down by each class.\nIn classifying the iris, we can use confusion_matrix() under module sklearn.metrics\n\nA confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix \nprint(confusion_matrix(y_test, y_pred))\n\n# Above operation can be graphically done as \nfrom sklearn.metrics import ConfusionMatrixDisplay\nmat = confusion_matrix(y_test, y_pred, labels=['iris-setosa', 'iris-versicolor', 'iris-virginica'])\ndisp = ConfusionMatrixDisplay(confusion_matrix=mat, display_labels=['iris-setosa', 'iris-versicolor', 'iris-virginica'])\ndisp.plot()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T16:33:22.861053Z","iopub.execute_input":"2023-09-21T16:33:22.861382Z","iopub.status.idle":"2023-09-21T16:33:23.103054Z","shell.execute_reply.started":"2023-09-21T16:33:22.861359Z","shell.execute_reply":"2023-09-21T16:33:23.101796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Confusion Matrix output Explanation:\n1. 1st Row represnts comparsion of y_test (true) with y_pred (our prediction) for 1st class (setosa),\nIt is 15 0 0 <- No false predictions were done here\n2. 2nd Row represnts comparsion of y_test (true) with y_pred (our prediction) for 2nd class (versicolor),\nIt is 0 15 0 <- No false predictions were done here\n3. 3rd Row represnts comparsion of y_test (true) with y_pred (our prediction) for 3rd class (virginica),\nIt is 0 1 14 <- 1 virginica falsely classified as versicolor","metadata":{}},{"cell_type":"markdown","source":"K-fold Cross Validation\n\nConventional cross validation - train-test split before fitting the model also known as holdout method. \n\nHowever, the split is random, as a result, model performance can be sensitive to how the data is split. To overcome this, we introduce k-fold cross validation.\n\nIn k fold cross validation: \n1. the data is divided into k subsets.\n2. Then the holdout method is repeated k times, such that each time, one of the k subsets is used as the test set and the other k-1 subsets are combined to train the model.\n3. Then the accuracy is averaged over k trials to provide total effectiveness of the model. \n\nIn this way, all data points are used; and there are more metrics so we don’t rely on one test data for model performance evaluation.\n\nAs a general rule, 5-fold or 10-fold cross validation is preferred; but there is no formal rule. As k gets larger, the difference in size between the training set and the resampling subsets gets smaller. As this difference decreases, the bias of the technique becomes smaller.\n","metadata":{}},{"cell_type":"code","source":"\"\"\" K Cross Validation \"\"\"\nfrom sklearn.model_selection import cross_val_score\n# create a new KNN model\nknn_cv = KNeighborsClassifier(n_neighbors=3)\n# train model with 5-fold cv (1 set - 20% data)\ncv_scores = cross_val_score(knn_cv, X, y, cv=5)\n# print each cv score (accuracy) \nprint(cv_scores)\nprint(cv_scores.mean())","metadata":{"execution":{"iopub.status.busy":"2023-09-21T16:40:16.758156Z","iopub.execute_input":"2023-09-21T16:40:16.758520Z","iopub.status.idle":"2023-09-21T16:40:16.808026Z","shell.execute_reply.started":"2023-09-21T16:40:16.758493Z","shell.execute_reply":"2023-09-21T16:40:16.806297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Grid Search \nWhat is the best k? \nFinding the optimal k is called tuning the hyperparameter. A handy tool is grid search. \nGridSearchCV, which trains our model multiple times on a range of values specified with the param_grid parameter and computes cross validation score, so that we can check which of our values for the tested hyperparameter performed the best.\nThe techniques of k-fold cross validation and tuning parameters with grid search is applicable to both classification and regression problems","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n# create new a knn model\nknn2 = KNeighborsClassifier()\n# create a dict of all values we want to test for n_neighbors\nparam_grid = {'n_neighbors': np.arange(2, 10)}\n# use gridsearch to test all values for n_neighbors\nknn_gscv = GridSearchCV(knn2, param_grid, cv=5)\n#fit model to data\nknn_gscv.fit(X, y)\nprint(knn_gscv.best_params_) # Top performing param\nprint(knn_gscv.best_score_) # Accuracy of model when k is 4\n\n# Now we are ready to build the final model\nknn_final = KNeighborsClassifier(n_neighbors=knn_gscv.best_params_['n_neighbors'])\nknn_final.fit(X, y)\n\ny_pred = knn_final.predict(X)\nprint(knn_final.score(X, y))","metadata":{"execution":{"iopub.status.busy":"2023-09-21T16:52:51.450259Z","iopub.execute_input":"2023-09-21T16:52:51.450629Z","iopub.status.idle":"2023-09-21T16:52:51.775777Z","shell.execute_reply.started":"2023-09-21T16:52:51.450600Z","shell.execute_reply":"2023-09-21T16:52:51.774350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Label Prediction with new Data","metadata":{}},{"cell_type":"code","source":"new_data = np.array([3.76, 1.20]) #New Data - petal len and petal width\nnew_data = new_data.reshape(1, -1)\nprint(knn_final.predict(new_data))\n\nprint(\"\\n\")\n\nnew_data = np.array([[3.76, 1.2], \n                     [5.25, 1.2],\n                     [1.58, 1.2]])\nprint(knn_final.predict(new_data))\nprint(\"\\n\")\nprint(knn_final.predict_proba(new_data))","metadata":{"execution":{"iopub.status.busy":"2023-09-21T17:13:47.932158Z","iopub.execute_input":"2023-09-21T17:13:47.932564Z","iopub.status.idle":"2023-09-21T17:13:47.949401Z","shell.execute_reply.started":"2023-09-21T17:13:47.932515Z","shell.execute_reply":"2023-09-21T17:13:47.947488Z"},"trusted":true},"execution_count":null,"outputs":[]}]}